{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting Scripts\n",
    "\n",
    "## Group-Level Analyses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import StudyII_All_5_note_Sets.paths as StudyII_paths\n",
    "import StudyI_Pentatonic_vs_Chromatic.paths as StudyI_paths\n",
    "import Study_Likert.paths as Study_likert_paths\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from Shared_Scripts.stat_funcs import *\n",
    "import scipy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "source": [
    "#Helper function for plot annotation\n",
    "def annotate(ax, data, x, y):\n",
    "    slope, intercept, rvalue, pvalue, stderr = scipy.stats.linregress(x=data[x], y=data[y])\n",
    "    ax.text(.02, .9, f'r2={rvalue ** 2:.2f}, p={pvalue:.2g}', transform=ax.transAxes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "studyI_GL = pd.read_csv(StudyI_paths.processed_dir + 'group_level_results.csv')\n",
    "studyII_GL = pd.read_csv(StudyII_paths.processed_dir + 'group_level_results.csv')\n",
    "study_likert = pd.read_csv(Study_likert_paths.processed_dir + 'set_level_results.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load data\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Actual Analyses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trial-Level Analyses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# No need to import if imported at top of page\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import StudyII_All_5_note_Sets.paths as StudyII_paths\n",
    "import StudyI_Pentatonic_vs_Chromatic.paths as StudyI_paths\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "source": [
    "studyI_TL = pd.read_pickle(StudyI_paths.processed_dir + 'single_trial_results.pickle')\n",
    "studyII_TL = pd.read_pickle(StudyII_paths.processed_dir + 'single_trial_results.pickle')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load data\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (optional) Remove decoy trials"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "source": [
    "studyI_TL = studyII_TL[studyII_TL['has_decoy'] == False]\n",
    "studyII_TL = studyII_TL[studyII_TL['has_decoy'] == False]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Ignore decoys\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "source": [
    "# Study II: Distribution of RT (of Nth percentile)\n",
    "N = 0.95\n",
    "temp = studyII_TL[['rt','chose']]\n",
    "percentile = temp['rt'].quantile(N)\n",
    "temp = temp[temp['rt']<percentile]\n",
    "temp = temp.rename(columns={'chose':'condition'})\n",
    "fig, ax = pyplot.subplots(figsize=(15, 8))\n",
    "sns.kdeplot(ax=ax, data=temp, x=\"rt\", hue=\"condition\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "source": [
    "# Study II: Rate of neither across all sets\n",
    "counts = studyII_TL.groupby('set')['chose'].value_counts().unstack()\n",
    "counts['total'] = counts['shifted'] + counts['swapped'] + counts['neither']\n",
    "counts['shifted_rate'] = counts['shifted'] / counts['total']\n",
    "counts['neither_rate'] = counts['neither'] / counts['total']\n",
    "counts['not_shifted_rate'] = 1 - counts['shifted_rate']\n",
    "counts = counts.reset_index().rename(columns={'index':'set'})\n",
    "plot_order = counts.sort_values(by=[\"neither_rate\"], ascending=False)['set'].values\n",
    "fig, ax = pyplot.subplots(figsize=(20, 12))\n",
    "sns.pointplot(ax=ax, y=\"set\", x=\"neither_rate\", data=counts, order=plot_order)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Plot rate_neither for each set\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "source": [
    "# Study II: RTs across all sets (Nth percentile)\n",
    "temp = studyII_TL\n",
    "N = 0.95\n",
    "percentile = temp['rt'].quantile(N)\n",
    "temp = temp[temp['rt']<percentile]\n",
    "mean = temp.groupby('set').mean()['rt'].reset_index().sort_values(by=\"rt\")\n",
    "plot_order = mean['set'].values\n",
    "fig, ax = pyplot.subplots(figsize=(20, 12))\n",
    "sns.pointplot(ax=ax, y=\"set\", x=\"rt\", data=temp, order=plot_order)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Group-Level Correlations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Covariance Matrices of chunks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "# Matrix of biases (Clusters)\n",
    "temp = studyII_GL\n",
    "\n",
    "K=5\n",
    "chunks = range(K)\n",
    "CHUNKS_BIAS_DELTA = np.empty((K,K,))\n",
    "CHUNKS_BIAS_DELTA[:] = np.nan\n",
    "CHUNKS_BIAS_DELTA = pd.DataFrame(CHUNKS_BIAS_DELTA, index=chunks, columns=chunks)\n",
    "for chunk1 in chunks:\n",
    "    for chunk2 in chunks:\n",
    "        set1_df = temp[temp['K_Means_5']==chunk1]\n",
    "        set2_df = temp[temp['K_Means_5']==chunk2]\n",
    "        X = np.mean(set1_df.groupby(\"set\").mean()['rate shifted - rate swapped (NN)'].values)\n",
    "        Y = np.mean(set2_df.groupby(\"set\").mean()['rate shifted - rate swapped (NN)'].values)\n",
    "        delta = abs(X-Y)\n",
    "        CHUNKS_BIAS_DELTA.at[chunk1, chunk2] = delta\n",
    "CHUNKS_BIAS_DELTA = CHUNKS_BIAS_DELTA.mask(np.triu(np.ones(CHUNKS_BIAS_DELTA.shape, dtype=np.bool_)))\n",
    "sns.heatmap(CHUNKS_BIAS_DELTA, cmap=sns.color_palette(\"rocket_r\", as_cmap=True), square=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "source": [
    "# Matrix of biases (All 66)\n",
    "temp = studyII_GL\n",
    "\n",
    "sets = temp.groupby('set').mean().sort_values(by=\"rate shifted - rate swapped (NN)\").index.values\n",
    "\n",
    "ALL_SETS_BIAS = np.empty((66,66,))\n",
    "ALL_SETS_BIAS[:] = np.nan\n",
    "ALL_SETS_BIAS = pd.DataFrame(ALL_SETS_BIAS, index=sets, columns=sets)\n",
    "\n",
    "for set1_name in sets:\n",
    "    for set2_name in sets:\n",
    "        set1_df = temp[temp['set']==set1_name]\n",
    "        set2_df = temp[temp['set']==set2_name]\n",
    "        X = np.mean(set1_df.groupby(\"set\").mean()['rate shifted - rate swapped (NN)'].values)\n",
    "        Y = np.mean(set2_df.groupby(\"set\").mean()['rate shifted - rate swapped (NN)'].values)\n",
    "        delta = abs(X-Y)\n",
    "        ALL_SETS_BIAS.at[set1_name, set2_name] = delta\n",
    "\n",
    "ALL_SETS_BIAS = ALL_SETS_BIAS.mask(np.triu(np.ones(ALL_SETS_BIAS.shape, dtype=np.bool_)))\n",
    "sns.heatmap(ALL_SETS_BIAS, cmap=sns.color_palette(\"rocket_r\", as_cmap=True), square=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "# Matrix of median dissonance\n",
    "temp = studyII_GL\n",
    "\n",
    "K=5\n",
    "chunks = range(K)\n",
    "CHUNKS_DISSONANCE_DELTA = np.empty((K,K,))\n",
    "CHUNKS_DISSONANCE_DELTA[:] = np.nan\n",
    "CHUNKS_DISSONANCE_DELTA = pd.DataFrame(CHUNKS_DISSONANCE_DELTA, index=chunks, columns=chunks)\n",
    "for chunk1 in chunks:\n",
    "    for chunk2 in chunks:\n",
    "        set1_df = temp[temp['K_Means_5']==chunk1]\n",
    "        set2_df = temp[temp['K_Means_5']==chunk2]\n",
    "        X = np.mean(set1_df.groupby(\"set\").mean()['Dissonance Median'].values)\n",
    "        Y = np.mean(set2_df.groupby(\"set\").mean()['Dissonance Median'].values)\n",
    "        delta = abs(X-Y)\n",
    "        CHUNKS_DISSONANCE_DELTA.at[chunk1, chunk2] = delta\n",
    "CHUNKS_DISSONANCE_DELTA = CHUNKS_DISSONANCE_DELTA.mask(np.triu(np.ones(CHUNKS_DISSONANCE_DELTA.shape, dtype=np.bool_)))\n",
    "sns.heatmap(CHUNKS_DISSONANCE_DELTA, cmap=sns.color_palette(\"rocket_r\", as_cmap=True), square=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "# Matrix of dissonance deltas (All 66)\n",
    "temp = studyII_GL\n",
    "\n",
    "sets = temp.groupby('set').mean().sort_values(by=\"rate shifted - rate swapped (NN)\").index.values\n",
    "\n",
    "ALL_SETS_DISSONANCE = np.empty((66,66,))\n",
    "ALL_SETS_DISSONANCE[:] = np.nan\n",
    "ALL_SETS_DISSONANCE = pd.DataFrame(ALL_SETS_DISSONANCE, index=sets, columns=sets)\n",
    "\n",
    "for set1_name in sets:\n",
    "    for set2_name in sets:\n",
    "        set1_df = temp[temp['set']==set1_name]\n",
    "        set2_df = temp[temp['set']==set2_name]\n",
    "        X = np.mean(set1_df.groupby(\"set\").mean()['Dissonance Median'].values)\n",
    "        Y = np.mean(set2_df.groupby(\"set\").mean()['Dissonance Median'].values)\n",
    "        delta = abs(X-Y)\n",
    "        ALL_SETS_DISSONANCE.at[set1_name, set2_name] = delta\n",
    "\n",
    "ALL_SETS_DISSONANCE = ALL_SETS_DISSONANCE.mask(np.triu(np.ones(ALL_SETS_DISSONANCE.shape, dtype=np.bool_)))\n",
    "sns.heatmap(ALL_SETS_DISSONANCE, cmap=sns.color_palette(\"rocket_r\", as_cmap=True), square=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "# Matrix of P5s\n",
    "temp = studyII_GL\n",
    "\n",
    "K=5\n",
    "chunks = range(K)\n",
    "CHUNKS_P5_DELTA = np.empty((K,K,))\n",
    "CHUNKS_P5_DELTA[:] = np.nan\n",
    "CHUNKS_P5_DELTA = pd.DataFrame(CHUNKS_P5_DELTA, index=chunks, columns=chunks)\n",
    "for chunk1 in chunks:\n",
    "    for chunk2 in chunks:\n",
    "        set1_df = temp[temp['K_Means_5']==chunk1]\n",
    "        set2_df = temp[temp['K_Means_5']==chunk2]\n",
    "        X = np.mean(set1_df.groupby(\"set\").mean()['# IC 5'].values)\n",
    "        Y = np.mean(set2_df.groupby(\"set\").mean()['# IC 5'].values)\n",
    "        delta = abs(X-Y)\n",
    "        CHUNKS_P5_DELTA.at[chunk1, chunk2] = delta\n",
    "CHUNKS_P5_DELTA = CHUNKS_P5_DELTA.mask(np.triu(np.ones(CHUNKS_P5_DELTA.shape, dtype=np.bool_)))\n",
    "sns.heatmap(CHUNKS_P5_DELTA, cmap=sns.color_palette(\"rocket_r\", as_cmap=True), square=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "# Matrix of P5 deltas (All 66)\n",
    "temp = studyII_GL\n",
    "\n",
    "sets = temp.groupby('set').mean().sort_values(by=\"rate shifted - rate swapped (NN)\").index.values\n",
    "\n",
    "ALL_SETS_P5 = np.empty((66,66,))\n",
    "ALL_SETS_P5[:] = np.nan\n",
    "ALL_SETS_P5 = pd.DataFrame(ALL_SETS_P5, index=sets, columns=sets)\n",
    "\n",
    "for set1_name in sets:\n",
    "    for set2_name in sets:\n",
    "        set1_df = temp[temp['set']==set1_name]\n",
    "        set2_df = temp[temp['set']==set2_name]\n",
    "        X = np.mean(set1_df.groupby(\"set\").mean()['# IC 5'].values)\n",
    "        Y = np.mean(set2_df.groupby(\"set\").mean()['# IC 5'].values)\n",
    "        delta = abs(X-Y)\n",
    "        ALL_SETS_P5.at[set1_name, set2_name] = delta\n",
    "\n",
    "ALL_SETS_P5 = ALL_SETS_P5.mask(np.triu(np.ones(ALL_SETS_P5.shape, dtype=np.bool_)))\n",
    "sns.heatmap(ALL_SETS_P5, cmap=sns.color_palette(\"rocket_r\", as_cmap=True), square=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "# Cluster matrix comparison\n",
    "\n",
    "bias = CHUNKS_BIAS_DELTA.to_numpy().flatten()\n",
    "bias = bias[~np.isnan(bias)]\n",
    "\n",
    "\n",
    "dissonance = CHUNKS_DISSONANCE_DELTA.to_numpy().flatten()\n",
    "dissonance = dissonance[~np.isnan(dissonance)]\n",
    "\n",
    "P5 = CHUNKS_P5_DELTA.to_numpy().flatten()\n",
    "P5 = P5[~np.isnan(P5)]\n",
    "\n",
    "bias_dissonance_corr = 1-st.permtest_corr(bias,dissonance,10000)[0]\n",
    "bias_P5_corr = 1-st.permtest_corr(bias,P5,10000)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "source": [
    "# All sets matrix comparison\n",
    "\n",
    "bias = ALL_SETS_BIAS.to_numpy().flatten()\n",
    "bias = bias[~np.isnan(bias)]\n",
    "\n",
    "\n",
    "dissonance = ALL_SETS_DISSONANCE.to_numpy().flatten()\n",
    "dissonance = dissonance[~np.isnan(dissonance)]\n",
    "\n",
    "P5 = ALL_SETS_P5.to_numpy().flatten()\n",
    "P5 = P5[~np.isnan(P5)]\n",
    "\n",
    "bias_dissonance_corr = 1-st.permtest_corr(bias,dissonance,10000)[0]\n",
    "bias_P5_corr = 1-st.permtest_corr(bias,P5,10000)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Statistics\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Study II: Get correlation of every half of subjects on rate_shifted\n",
    "\n",
    "temp = studyII_GL\n",
    "temp = studyII_GL[['subject', 'rate shifted - rate swapped (NN)', 'set', 'section']]\n",
    "temp1 = temp.groupby('set').mean().sort_values(by='rate shifted - rate swapped (NN)')\n",
    "worst = [*temp1.index.values[0:10]]\n",
    "best = [*temp1.index.values[-10:]]\n",
    "all = temp1.index.values\n",
    "sets = worst + best\n",
    "temp = temp[temp['set'].isin(sets)]\n",
    "how_many = temp.groupby(\"set\").first().shape[0]\n",
    "X = temp[temp['section'].isin([0, 1, 2])].groupby('set')[\n",
    "    'rate shifted - rate swapped (NN)'].mean().sort_index().to_frame().reset_index().rename(\n",
    "    columns={'rate shifted - rate swapped (NN)': 'X'})\n",
    "Y = temp[temp['section'].isin([3, 4, 5])].groupby('set')[\n",
    "    'rate shifted - rate swapped (NN)'].mean().sort_index().to_frame().reset_index().rename(\n",
    "    columns={'rate shifted - rate swapped (NN)': 'Y'})\n",
    "both = pd.merge(X, Y, on='set')\n",
    "R, P = stats.pearsonr(both['X'], both['Y'])\n",
    "print(\"R={}, P={}\".format(R, P))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "importlib.reload(st)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "\n",
    "temp = studyII_GL\n",
    "\n",
    "set = \"0 2 4 5 6\"\n",
    "\n",
    "temp2 = temp[temp['set']==set]\n",
    "X = temp2['rate_NN_shifted'].values\n",
    "Y = temp2['rate_NN_swapped'].values\n",
    "obs_stat, p = st.perm_bias_paired(X,Y,10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "source": [
    "temp = studyII_GL\n",
    "\n",
    "sets = temp.groupby('set').mean().sort_values(by=\"rate shifted - rate swapped (NN)\").index.values\n",
    "\n",
    "ALL_SETS_P = np.empty((66,66,))\n",
    "ALL_SETS_P[:] = np.nan\n",
    "ALL_SETS_P = pd.DataFrame(ALL_SETS_P, index=sets, columns=sets)\n",
    "\n",
    "ALL_SETS_OBS = np.empty((66,66,))\n",
    "ALL_SETS_OBS[:] = np.nan\n",
    "ALL_SETS_OBS = pd.DataFrame(ALL_SETS_OBS, index=sets, columns=sets)\n",
    "\n",
    "total_tests = 66*66\n",
    "current_test = 1\n",
    "\n",
    "for set1_name in sets:\n",
    "    for set2_name in sets:\n",
    "        print(\"\\rcompleted {}%\".format(round((current_test/total_tests)*100)),end='')\n",
    "        set1_df = temp[temp['set']==set1_name]\n",
    "        set2_df = temp[temp['set']==set2_name]\n",
    "        X = set1_df['rate shifted - rate swapped (NN)'].values\n",
    "        Y = set2_df['rate shifted - rate swapped (NN)'].values\n",
    "        obs_stat, p = st.perm_bias_unpaired(X,Y,10000,loud=False)\n",
    "        ALL_SETS_OBS.at[set1_name, set2_name] = obs_stat\n",
    "        ALL_SETS_P.at[set1_name, set2_name] = p\n",
    "        current_test += 1\n",
    "\n",
    "ALL_SETS_P.to_csv(StudyII_paths.processed_dir + 'all_sets_p.csv')\n",
    "ALL_SETS_OBS.to_csv(StudyII_paths.processed_dir + 'all_sets_obs.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "fig, ax = pyplot.subplots(figsize=(10, 10))\n",
    "sns.heatmap(ALL_SETS_P, cmap=sns.color_palette(\"rocket_r\", as_cmap=True), ax=ax,vmin=0, vmax=0.05, square=True)\n",
    "plt.savefig(StudyII_paths.plots_dir + \"set_p_matrix.svg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "temp = studyII_GL\n",
    "\n",
    "N=4\n",
    "\n",
    "sets = temp.groupby('set').mean().sort_values(by=\"rate shifted - rate swapped (NN)\").index.values\n",
    "chunk_names = np.array_split(sets,N)\n",
    "\n",
    "column_names = [\"chunk {}\".format(i+1) for i,_ in enumerate(chunk_names)]\n",
    "\n",
    "ALL_CHUNKS_P = np.empty((N,N,))\n",
    "ALL_CHUNKS_P[:] = np.nan\n",
    "ALL_CHUNKS_P = pd.DataFrame(ALL_CHUNKS_P, index=column_names, columns=column_names)\n",
    "\n",
    "ALL_CHUNKS_OBS = np.empty((N,N,))\n",
    "ALL_CHUNKS_OBS[:] = np.nan\n",
    "ALL_CHUNKS_OBS = pd.DataFrame(ALL_CHUNKS_OBS, index=column_names, columns=column_names)\n",
    "\n",
    "total_tests = N*N\n",
    "current_test = 1\n",
    "\n",
    "for i, set1_names in enumerate(chunk_names):\n",
    "    for j, set2_names in enumerate(chunk_names):\n",
    "        print(\"\\rcompleted {}%\".format(round((current_test/total_tests)*100)),end='')\n",
    "        set1_df = temp[temp['set'].isin(set1_names)]\n",
    "        set2_df = temp[temp['set'].isin(set2_names)]\n",
    "        X = set1_df['rate shifted - rate swapped (NN)'].values\n",
    "        Y = set2_df['rate shifted - rate swapped (NN)'].values\n",
    "        obs_stat, p = st.perm_bias_unpaired(X,Y,10000,loud=False)\n",
    "        ALL_CHUNKS_OBS.at[\"chunk {}\".format(i+1), \"chunk {}\".format(j+1)] = obs_stat\n",
    "        ALL_CHUNKS_P.at[\"chunk {}\".format(i+1), \"chunk {}\".format(j+1)] = p\n",
    "        current_test += 1\n",
    "\n",
    "\n",
    "ALL_CHUNKS_P.to_csv(StudyII_paths.processed_dir + '{}_chunks_p.csv'.format(N))\n",
    "ALL_CHUNKS_OBS.to_csv(StudyII_paths.processed_dir + '{}_chunks_obs.csv'.format(N))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "fig, ax = pyplot.subplots()\n",
    "sns.heatmap(ALL_CHUNKS_P, cmap=sns.color_palette(\"rocket_r\", as_cmap=True), square=True, ax=ax,vmin=0, vmax=0.05)\n",
    "plt.savefig(StudyII_paths.plots_dir + \"5_chunk_p_matrix.svg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
